{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f500dd6",
   "metadata": {},
   "source": [
    "# Blog Post 2\n",
    "In this blog post, we are going to create a spider object, which is useful for scraping the web! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a48509",
   "metadata": {},
   "source": [
    "For starters, here are the packages we are going to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8cdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d9a91",
   "metadata": {},
   "source": [
    "## The Big Picture\n",
    "Let's take a look at our finished product first, before we break down how it works! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2014738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbSpider(scrapy.Spider):\n",
    "    name = 'imdb_spider'\n",
    "    \n",
    "    start_urls = ['https://www.imdb.com/title/tt1160419/']\n",
    "    \n",
    "    def parse(self,response):\n",
    "        \"\"\"\n",
    "        assumes you start on a movie page, navigate to Cast & Crew page\n",
    "        once at <movie_url>fullcredits, call parse_full_Credits method in the callback argument \n",
    "        to a yielded scrapy.Request. returns nothing, around 5 lines of code\n",
    "        \"\"\"\n",
    "        #gets link to cast and crew from start page \n",
    "        cast_crew = response.css(\"a[href^= 'fullcredits']\").attrib[\"href\"] \n",
    "        if cast_crew:\n",
    "            #joins link to existing link\n",
    "            cast_crew = response.urljoin(cast_crew)\n",
    "\n",
    "            #yields request: if this page exists, navigate to it and perform whatever function is described in the callback argument\n",
    "            yield scrapy.Request(cast_crew, callback = self.parse_full_credits)\n",
    "\n",
    "\n",
    "    def parse_full_credits(self,response):\n",
    "        \"\"\"\n",
    "        assumes you start on cast and crew page \n",
    "        yields a scraoy.Request for the page of each actor listed on parse_actor_page\n",
    "        No crew, just actors \n",
    "        returns nothing, around 5 lines of code\n",
    "        \"\"\"\n",
    "\n",
    "        #below code gathers a list of urls for actors from cast page\n",
    "        cast_list = [a.attrib[\"href\"] for a in response.css(\"td.primary_photo a\")] \n",
    "        for actor in cast_list:\n",
    "        #for each actors url in the list, join it to the existing response url\n",
    "            actor_page = response.urljoin(actor)\n",
    "            #for each actor, yield a request: go to new response url, and perform parse_actor_page function\n",
    "            yield scrapy.Request(actor_page, callback = self.parse_actor_page)\n",
    "\n",
    "\n",
    "    def parse_actor_page(self,response):\n",
    "        \"\"\"\n",
    "        start on the page of an actor, yields a dictionary of form {\"actor\": actor_name, \"movie_or_TV_name\": movie_or_TV_name}\n",
    "        should yield one such dict for each of the movies or tv shows on which the actor has worked.Name has to be determined of the actor \n",
    "        and each movie or tv show \n",
    "        no more than 15 lines of code \n",
    "        \"\"\"\n",
    "        #retrieve actor name from header\n",
    "        actor = response.css(\"h1.header span.itemprop::text\").get()\n",
    "\n",
    "        #get list of movies actor was involved with\n",
    "        movies = response.css(\"div.filmo-row\")\n",
    "        for movie in movies:\n",
    "            #see how the actor contributed to the movie, we are interested only in acting credits\n",
    "            role = movie.css(\"::attr(id)\").get()[0:3] \n",
    "            if(role == 'act'): #to account for 'ACT'or and 'ACT'ress \n",
    "                yield{\n",
    "                    \"actor\":actor, #specified above \n",
    "                    \"movie_or_TV_name\": movie.css(\"a::text\").get() #get movie title\n",
    "                }\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad8da6",
   "metadata": {},
   "source": [
    "The 'name' and 'start_urls' variables tell the program what to call the spider when you want to run it and what the first link to look at is! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ad831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4beff520",
   "metadata": {},
   "source": [
    "## The Parse Method \n",
    "The parse method is designed to retrieve the \"Cast and Crew\" link from our starting IMDB page, and then yield a scrapy.Request to tell the spider what to when we get to that page, in our case, we want to use the parse_full_credits() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40d95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(self,response):\n",
    "        \"\"\"\n",
    "        assumes you start on a movie page, navigate to Cast & Crew page\n",
    "        once at <movie_url>fullcredits, call parse_full_Credits method in the callback argument \n",
    "        to a yielded scrapy.Request. returns nothing, around 5 lines of code\n",
    "        \"\"\"\n",
    "        #gets link to cast and crew from start page \n",
    "        cast_crew = response.css(\"a[href^= 'fullcredits']\").attrib[\"href\"] \n",
    "        if cast_crew:\n",
    "            #joins link to existing link\n",
    "            cast_crew = response.urljoin(cast_crew)\n",
    "\n",
    "            #yields request: if this page exists, navigate to it and perform whatever function is described in the callback argument\n",
    "            yield scrapy.Request(cast_crew, callback = self.parse_full_credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802527cc",
   "metadata": {},
   "source": [
    "The response.urljoin() function joins the cast_crew url that we scraped from the IMDB page and combines it with the start_url! Then we navigate to the said link, and using the callback argument of the scrapy.Request() method, we instruct the spider what to do once we get there!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69572165",
   "metadata": {},
   "source": [
    "## The parse_full_credits() Method\n",
    "This method is designed to get the list of actors/actresses from the Cast and Crew page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_full_credits(self,response):\n",
    "        \"\"\"\n",
    "        assumes you start on cast and crew page \n",
    "        yields a scraoy.Request for the page of each actor listed on parse_actor_page\n",
    "        No crew, just actors \n",
    "        returns nothing, around 5 lines of code\n",
    "        \"\"\"\n",
    "\n",
    "        #below code gathers a list of urls for actors from cast page\n",
    "        cast_list = [a.attrib[\"href\"] for a in response.css(\"td.primary_photo a\")] \n",
    "        for actor in cast_list:\n",
    "            #for each actors url in the list, join it to the existing response url\n",
    "            actor_page = response.urljoin(actor)\n",
    "            #for each actor, yield a request: go to new response url, and perform parse_actor_page function\n",
    "            yield scrapy.Request(actor_page, callback = self.parse_actor_page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B] *",
   "language": "python",
   "name": "conda-env-PIC16B-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
